<!doctype html>
<html lang="pt">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Alma – Texto, Voz e Imagem</title>
  <style>
    :root { color-scheme: light dark; }
    body { font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
           margin: 24px; line-height: 1.45; }
    h1 { font-size: 2.2rem; margin: 0 0 16px; }
    .wrap { display: grid; gap: 16px; max-width: 900px; }
    .row { display: grid; grid-template-columns: 1fr auto; gap: 8px; align-items: center; }
    input[type="text"] { font-size: 1.05rem; padding: 10px 12px; border-radius: 8px; border: 1px solid #ccc; }
    button { padding: 10px 14px; border-radius: 8px; border: none; background: #2563eb; color: #fff; font-weight: 600; cursor: pointer; }
    button:disabled { opacity: 0.6; cursor: default; }
    .cols { display: grid; grid-template-columns: 1fr 360px; gap: 20px; align-items: start; }
    .panel { border: 1px solid #ddd; border-radius: 12px; padding: 12px; min-height: 220px; }
    .msg { white-space: pre-wrap; }
    figure { margin: 0; }
    img { width: 100%; height: auto; border-radius: 12px; border: 1px solid #ddd; display: block; }
    .muted { opacity: .75; font-size: .9rem; }
    .error { color: #b91c1c; font-weight: 600; }
    .ok { color: #047857; font-weight: 600; }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Alma</h1>

    <div class="row">
      <input id="q" type="text" placeholder="Escreve a tua pergunta…" />
      <button id="askBtn">Perguntar</button>
    </div>

    <div class="cols">
      <section class="panel">
        <div id="status" class="muted">Pronta ✅</div>
        <div id="textOut" class="msg" style="margin-top:8px;"></div>
        <audio id="player" controls style="width:100%; margin-top:12px;"></audio>
      </section>

      <aside>
        <figure>
          <img id="portrait"
               alt="Alma"
               src="https://raw.githubusercontent.com/ruirocha-coder/imagens/refs/heads/main/ruirocha1919_cyber_punk_A_confident_and_elegant_woman_in_her_mi_2c33d2b6-33be-429b-887e-7c2bb64953da.png" />
          <figcaption class="muted" style="margin-top:6px;">
            Retrato usado no D-ID para sincronização labial.
          </figcaption>
        </figure>
      </aside>
    </div>

    <details>
      <summary>Diagnóstico</summary>
      <pre id="diag" style="white-space:pre-wrap"></pre>
    </details>
  </div>

  <script>
    // ===================== PARÂMETROS (já preenchidos) =====================
    // Backend de NLP (Grok via FastAPI):
    const NLP_API = "https://alma-server-alma-1.up.railway.app"; // POST /ask {question}

    // Backend de TTS (D-ID wrapper no Railway):
    const TTS_API = "https://almabody-alma-1.up.railway.app";    // POST /say {text, image_url?, voice_id?}

    // Imagem (RAW do GitHub) para sincronização labial:
    const IMAGE_URL = "https://raw.githubusercontent.com/ruirocha-coder/imagens/refs/heads/main/ruirocha1919_cyber_punk_A_confident_and_elegant_woman_in_her_mi_2c33d2b6-33be-429b-887e-7c2bb64953da.png";

    // Opcional: voz no D-ID (se tiveres uma específica). Caso não, deixa "" que o backend usa o default.
    const VOICE_ID = "";

    // ========================= UTILITÁRIOS UI ==============================
    const $ = (sel) => document.querySelector(sel);
    const qInput   = $("#q");
    const askBtn   = $("#askBtn");
    const outTxt   = $("#textOut");
    const statusEl = $("#status");
    const player   = $("#player");
    const diagEl   = $("#diag");

    function setStatus(text, kind = "muted") {
      statusEl.className = kind;
      statusEl.textContent = text;
    }
    function appendDiag(label, obj) {
      try {
        diagEl.textContent += `\n\n# ${label}\n` + JSON.stringify(obj, null, 2);
      } catch { /* ignore */ }
    }

    // ======================== CHAMADAS DE REDE =============================
    async function askAlma(question) {
      const url = `${NLP_API}/ask`;
      const res = await fetch(url, {
        method: "POST",
        headers: {"Content-Type":"application/json"},
        body: JSON.stringify({ question })
      });
      const text = await res.text();
      appendDiag("NLP raw", { status: res.status, body: text });

      if (!res.ok) throw new Error(`NLP falhou (${res.status}): ${text}`);
      const json = JSON.parse(text);
      // suporta {answer:"..."} ou {ok:true, answer:"..."}
      return json.answer || json.text || JSON.stringify(json);
    }

    async function speakAlma(text) {
      const url = `${TTS_API}/say`;
      const body = { text, image_url: IMAGE_URL };
      if (VOICE_ID) body.voice_id = VOICE_ID;

      const res = await fetch(url, {
        method: "POST",
        headers: {"Content-Type":"application/json"},
        body: JSON.stringify(body)
      });

      // Tenta detetar se veio áudio direto (audio/mpeg, audio/wav…)
      const ctype = res.headers.get("content-type") || "";
      if (res.ok && ctype.startsWith("audio/")) {
        const blob = await res.blob();
        appendDiag("TTS audio-blob", { status: res.status, type: ctype, size: blob.size });
        return URL.createObjectURL(blob);
      }

      // Caso venha JSON { url } ou { audio_url }
      const textRes = await res.text();
      appendDiag("TTS raw", { status: res.status, body: textRes });

      if (!res.ok) throw new Error(`TTS falhou (${res.status}): ${textRes}`);

      let j = {};
      try { j = JSON.parse(textRes); } catch {}
      const audioURL = j.url || j.audio_url || j.audio || null;
      if (!audioURL) throw new Error("TTS não devolveu áudio (esperava url/audio_url).");
      return audioURL;
    }

    // ============================ FLUXO UI =================================
    async function handleAsk() {
      const question = (qInput.value || "").trim();
      if (!question) return;

      askBtn.disabled = true;
      setStatus("A pensar…", "muted");
      outTxt.textContent = "";
      player.pause();
      player.removeAttribute("src");

      try {
        // 1) Perguntar ao Grok (texto)
        const answer = await askAlma(question);
        outTxt.textContent = answer;

        // 2) Falar no D-ID
        setStatus("A falar…", "muted");
        const audioUrl = await speakAlma(answer);

        player.src = audioUrl;
        await player.play().catch(() => {/* autoplay pode ser bloqueado; o user clica no play */});
        setStatus("Pronta ✅", "ok");
      } catch (err) {
        console.error(err);
        setStatus(`Erro: ${err.message || err}`, "error");
      } finally {
        askBtn.disabled = false;
      }
    }

    // Botão + Enter
    askBtn.addEventListener("click", handleAsk);
    qInput.addEventListener("keydown", (e) => {
      if (e.key === "Enter") handleAsk();
    });

    // Saúde rápida dos serviços
    (async () => {
      try {
        const h1 = await fetch(`${NLP_API}/health`).then(r => r.ok ? r.json() : null);
        const h2 = await fetch(`${TTS_API}/health`).then(r => r.ok ? r.json() : null);
        appendDiag("health NLP", h1);
        appendDiag("health TTS", h2);
      } catch {}
    })();
  </script>
</body>
</html>
